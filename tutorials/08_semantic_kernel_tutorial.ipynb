{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel Tutorial: Building AI Agents for Insurance\n",
    "\n",
    "This tutorial introduces **Semantic Kernel** by Microsoft, an SDK for integrating LLMs into applications using a \"kernel\" architecture with plugins and functions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Semantic Kernel concepts: Kernel, Plugins, and Functions\n",
    "2. Building Weather and Eligibility Agents\n",
    "3. Using Semantic Functions (prompt templates)\n",
    "4. DSPy Integration\n",
    "5. MLFlow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install semantic-kernel httpx beautifulsoup4 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "print(f\"Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Concepts\n",
    "\n",
    "- **Kernel**: Central orchestrator\n",
    "- **Plugins**: Collections of functions\n",
    "- **Native Functions**: Python functions\n",
    "- **Semantic Functions**: LLM prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "# Create kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Add chat service\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=\"chat\",\n",
    "        ai_model_id=model_name,\n",
    "        api_key=api_key,\n",
    "        base_url=api_base if api_base != \"https://api.openai.com/v1\" else None\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Kernel created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Native Functions (Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class WeatherPlugin:\n",
    "    \"\"\"Plugin for weather verification.\"\"\"\n",
    "    \n",
    "    @kernel_function(name=\"geocode\", description=\"Convert location to coordinates\")\n",
    "    def geocode(self, location: str) -> str:\n",
    "        try:\n",
    "            with httpx.Client() as client:\n",
    "                r = client.get(\n",
    "                    \"https://nominatim.openstreetmap.org/search\",\n",
    "                    params={\"q\": f\"{location}, Australia\", \"format\": \"json\", \"limit\": 1},\n",
    "                    headers={\"User-Agent\": \"InsuranceBot/1.0\"},\n",
    "                    timeout=10.0\n",
    "                )\n",
    "                if r.status_code == 200 and r.json():\n",
    "                    d = r.json()[0]\n",
    "                    return f\"Location: {d['display_name']}\\nLat: {d['lat']}\\nLon: {d['lon']}\"\n",
    "                return f\"Error: Location not found\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    @kernel_function(name=\"get_weather\", description=\"Get BOM weather data\")\n",
    "    def get_weather(self, latitude: str, longitude: str, date: str) -> str:\n",
    "        try:\n",
    "            year, month, day = date.split(\"-\")\n",
    "            url = \"https://reg.bom.gov.au/cgi-bin/climate/storms/get_storms.py\"\n",
    "            params = {\n",
    "                \"begin_day\": day, \"begin_month\": month, \"begin_year\": year,\n",
    "                \"end_day\": day, \"end_month\": month, \"end_year\": year,\n",
    "                \"lat\": float(latitude), \"lng\": float(longitude),\n",
    "                \"event\": \"all\", \"distance_from_point\": \"50\", \"states\": \"all\"\n",
    "            }\n",
    "            \n",
    "            with httpx.Client() as client:\n",
    "                r = client.get(url, params=params, timeout=15.0)\n",
    "                if r.status_code != 200:\n",
    "                    return f\"Error: HTTP {r.status_code}\"\n",
    "                \n",
    "                soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                events = [c[0].get_text(strip=True) for row in soup.find_all('tr')[1:]\n",
    "                         if (c := row.find_all('td')) and len(c) >= 2 and c[0].get_text(strip=True)]\n",
    "                \n",
    "                has_thunder = any('thunder' in e.lower() or 'lightning' in e.lower() for e in events)\n",
    "                has_wind = any('wind' in e.lower() or 'gust' in e.lower() for e in events)\n",
    "                \n",
    "                return f\"\"\"Date: {date}\n",
    "Events: {', '.join(events) if events else 'None'}\n",
    "Has Thunderstorm: {has_thunder}\n",
    "Has Strong Wind: {has_wind}\"\"\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "# Add plugin\n",
    "kernel.add_plugin(WeatherPlugin(), \"weather\")\n",
    "print(\"Weather plugin added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "weather_plugin = WeatherPlugin()\n",
    "\n",
    "geo_result = weather_plugin.geocode(\"Brisbane, QLD\")\n",
    "print(\"Geocode result:\")\n",
    "print(geo_result)\n",
    "\n",
    "weather_result = weather_plugin.get_weather(\"-27.4698\", \"153.0251\", \"2025-03-07\")\n",
    "print(\"\\nWeather result:\")\n",
    "print(weather_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Semantic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "\n",
    "# Weather report semantic function\n",
    "weather_prompt = \"\"\"You are a Weather Verification Agent.\n",
    "\n",
    "Given this data:\n",
    "Location: {{$location_data}}\n",
    "Weather: {{$weather_data}}\n",
    "\n",
    "Create a structured weather verification report including:\n",
    "- Location and coordinates\n",
    "- Date\n",
    "- Events found\n",
    "- Thunderstorm status\n",
    "- Strong wind status\"\"\"\n",
    "\n",
    "weather_func = kernel.add_function(\n",
    "    function_name=\"generate_report\",\n",
    "    plugin_name=\"reports\",\n",
    "    prompt=weather_prompt,\n",
    "    prompt_execution_settings=OpenAIChatPromptExecutionSettings(\n",
    "        service_id=\"chat\",\n",
    "        max_tokens=500\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Weather report function added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eligibility semantic function\n",
    "eligibility_prompt = \"\"\"You are a Claims Eligibility Agent.\n",
    "\n",
    "Rules:\n",
    "- APPROVED: Both thunderstorms AND strong winds detected in Australia\n",
    "- REVIEW: Only one severe weather type detected\n",
    "- DENIED: No severe weather or outside Australia\n",
    "\n",
    "Weather Report:\n",
    "{{$weather_report}}\n",
    "\n",
    "Provide:\n",
    "1. DECISION: APPROVED, REVIEW, or DENIED\n",
    "2. REASONING: Brief explanation\n",
    "3. CONFIDENCE: High, Medium, or Low\"\"\"\n",
    "\n",
    "eligibility_func = kernel.add_function(\n",
    "    function_name=\"determine_eligibility\",\n",
    "    plugin_name=\"claims\",\n",
    "    prompt=eligibility_prompt,\n",
    "    prompt_execution_settings=OpenAIChatPromptExecutionSettings(\n",
    "        service_id=\"chat\",\n",
    "        max_tokens=300\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Eligibility function added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_claim(location: str, date: str):\n",
    "    \"\"\"Process claim through Semantic Kernel.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Processing: {location} on {date}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Geocode\n",
    "    plugin = WeatherPlugin()\n",
    "    geo_result = plugin.geocode(location)\n",
    "    print(f\"\\nGeocoded:\\n{geo_result}\")\n",
    "    \n",
    "    # Extract lat/lon\n",
    "    lat, lon = None, None\n",
    "    for line in geo_result.split('\\n'):\n",
    "        if line.startswith('Lat:'):\n",
    "            lat = line.split(':')[1].strip()\n",
    "        elif line.startswith('Lon:'):\n",
    "            lon = line.split(':')[1].strip()\n",
    "    \n",
    "    if not lat or not lon:\n",
    "        return {\"error\": \"Failed to geocode\"}\n",
    "    \n",
    "    # Step 2: Get weather\n",
    "    weather_data = plugin.get_weather(lat, lon, date)\n",
    "    print(f\"\\nWeather:\\n{weather_data}\")\n",
    "    \n",
    "    # Step 3: Generate report\n",
    "    report_result = await kernel.invoke(\n",
    "        weather_func,\n",
    "        location_data=geo_result,\n",
    "        weather_data=weather_data\n",
    "    )\n",
    "    weather_report = str(report_result)\n",
    "    print(f\"\\nReport:\\n{weather_report}\")\n",
    "    \n",
    "    # Step 4: Eligibility\n",
    "    elig_result = await kernel.invoke(\n",
    "        eligibility_func,\n",
    "        weather_report=weather_report\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DECISION:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(str(elig_result))\n",
    "    \n",
    "    return {\n",
    "        \"weather_report\": weather_report,\n",
    "        \"decision\": str(elig_result)\n",
    "    }\n",
    "\n",
    "# Run\n",
    "result = await process_claim(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. DSPy Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "dspy_lm = dspy.LM(model=f\"openai/{model_name}\", api_key=api_key, api_base=api_base)\n",
    "dspy.configure(lm=dspy_lm)\n",
    "\n",
    "class EligSig(dspy.Signature):\n",
    "    \"\"\"CAT event eligibility.\"\"\"\n",
    "    weather_report: str = dspy.InputField()\n",
    "    decision: str = dspy.OutputField(desc=\"APPROVED/REVIEW/DENIED\")\n",
    "    reasoning: str = dspy.OutputField()\n",
    "\n",
    "elig_mod = dspy.ChainOfThought(EligSig)\n",
    "\n",
    "# Quick test\n",
    "r = elig_mod(weather_report=\"Brisbane. Thunder, Wind. Has Thunderstorm: True. Has Strong Wind: True.\")\n",
    "print(f\"DSPy: {r.decision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(weather_report=\"Thunder+Wind. Both: True\", decision=\"APPROVED\", reasoning=\"Both met\").with_inputs(\"weather_report\"),\n",
    "    dspy.Example(weather_report=\"Rain only. Both: False\", decision=\"DENIED\", reasoning=\"No severe\").with_inputs(\"weather_report\"),\n",
    "    dspy.Example(weather_report=\"Thunder only. Wind: False\", decision=\"REVIEW\", reasoning=\"One met\").with_inputs(\"weather_report\"),\n",
    "]\n",
    "\n",
    "metric = lambda ex, pred, trace=None: ex.decision.upper() == pred.decision.upper()\n",
    "optimizer = BootstrapFewShot(metric=metric, max_bootstrapped_demos=2)\n",
    "optimized_mod = optimizer.compile(elig_mod, trainset=examples)\n",
    "\n",
    "print(\"DSPy module optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MLFlow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_experiment(\"semantic-kernel-claims\")\n",
    "\n",
    "async def run_tracked(location: str, date: str):\n",
    "    with mlflow.start_run(run_name=f\"sk_{location.split(',')[0]}\"):\n",
    "        mlflow.log_params({\"framework\": \"semantic-kernel\", \"model\": model_name, \"location\": location})\n",
    "        \n",
    "        start = datetime.now()\n",
    "        result = await process_claim(location, date)\n",
    "        duration = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        decision = \"UNKNOWN\"\n",
    "        for d in [\"APPROVED\", \"DENIED\", \"REVIEW\"]:\n",
    "            if d in result.get(\"decision\", \"\").upper():\n",
    "                decision = d\n",
    "                break\n",
    "        \n",
    "        mlflow.log_metrics({\"duration\": duration})\n",
    "        mlflow.set_tags({\"decision\": decision})\n",
    "        \n",
    "        print(f\"Logged: {decision}, {duration:.2f}s\")\n",
    "        return result\n",
    "\n",
    "await run_tracked(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Covered\n",
    "- Kernel, plugins, native/semantic functions\n",
    "- Tool definition via `@kernel_function`\n",
    "- Prompt templates\n",
    "- DSPy + MLFlow integration\n",
    "\n",
    "### Strengths\n",
    "- Enterprise-ready (Microsoft)\n",
    "- Clear separation of concerns\n",
    "- Good for .NET/C# integration\n",
    "\n",
    "### Challenges\n",
    "- More verbose than simpler frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tutorial complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
