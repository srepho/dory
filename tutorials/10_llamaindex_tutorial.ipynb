{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex Tutorial: Building AI Agents for Insurance\n",
    "\n",
    "This tutorial introduces **LlamaIndex**, a framework originally focused on RAG but now with robust agent capabilities. LlamaIndex excels at connecting LLMs with data sources.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. LlamaIndex agents and tool concepts\n",
    "2. Building Weather and Eligibility Agents\n",
    "3. Sequential agent pipelines\n",
    "4. DSPy Integration\n",
    "5. MLFlow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-llms-openai llama-index-agent-openai\n",
    "# !pip install httpx beautifulsoup4 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "# Set for LlamaIndex\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "print(f\"Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Concepts\n",
    "\n",
    "LlamaIndex uses:\n",
    "- **FunctionTool**: Wrap Python functions as tools\n",
    "- **OpenAIAgent**: Agent that uses OpenAI function calling\n",
    "- **ReActAgent**: Agent using ReAct pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Create LLM\n",
    "llm = OpenAI(\n",
    "    model=model_name,\n",
    "    api_key=api_key,\n",
    "    api_base=api_base if api_base != \"https://api.openai.com/v1\" else None\n",
    ")\n",
    "\n",
    "# Test\n",
    "response = llm.complete(\"What is 2+2?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def geocode_location(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a location name to coordinates.\n",
    "    \n",
    "    Args:\n",
    "        location: Address or place name\n",
    "    \n",
    "    Returns:\n",
    "        String with location and coordinates\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with httpx.Client() as client:\n",
    "            r = client.get(\n",
    "                \"https://nominatim.openstreetmap.org/search\",\n",
    "                params={\"q\": f\"{location}, Australia\", \"format\": \"json\", \"limit\": 1},\n",
    "                headers={\"User-Agent\": \"InsuranceBot/1.0\"},\n",
    "                timeout=10.0\n",
    "            )\n",
    "            if r.status_code == 200 and r.json():\n",
    "                d = r.json()[0]\n",
    "                return f\"Location: {d['display_name']}\\nLatitude: {d['lat']}\\nLongitude: {d['lon']}\"\n",
    "            return \"Error: Location not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def get_bom_weather(latitude: str, longitude: str, date: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch weather from BOM.\n",
    "    \n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "        date: Date in YYYY-MM-DD format\n",
    "    \n",
    "    Returns:\n",
    "        Weather report\n",
    "    \"\"\"\n",
    "    try:\n",
    "        year, month, day = date.split(\"-\")\n",
    "        url = \"https://reg.bom.gov.au/cgi-bin/climate/storms/get_storms.py\"\n",
    "        params = {\n",
    "            \"begin_day\": day, \"begin_month\": month, \"begin_year\": year,\n",
    "            \"end_day\": day, \"end_month\": month, \"end_year\": year,\n",
    "            \"lat\": float(latitude), \"lng\": float(longitude),\n",
    "            \"event\": \"all\", \"distance_from_point\": \"50\", \"states\": \"all\"\n",
    "        }\n",
    "        \n",
    "        with httpx.Client() as client:\n",
    "            r = client.get(url, params=params, timeout=15.0)\n",
    "            if r.status_code != 200:\n",
    "                return f\"Error: HTTP {r.status_code}\"\n",
    "            \n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            events = []\n",
    "            for row in soup.find_all('tr')[1:]:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) >= 2:\n",
    "                    event = cells[0].get_text(strip=True)\n",
    "                    if event:\n",
    "                        events.append(event)\n",
    "            \n",
    "            has_thunder = any('thunder' in e.lower() or 'lightning' in e.lower() for e in events)\n",
    "            has_wind = any('wind' in e.lower() or 'gust' in e.lower() for e in events)\n",
    "            \n",
    "            return f\"\"\"Date: {date}\n",
    "Events: {', '.join(events) if events else 'None'}\n",
    "Has Thunderstorm: {has_thunder}\n",
    "Has Strong Wind: {has_wind}\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Create FunctionTools\n",
    "geocode_tool = FunctionTool.from_defaults(fn=geocode_location)\n",
    "weather_tool = FunctionTool.from_defaults(fn=get_bom_weather)\n",
    "\n",
    "print(f\"Tools: {geocode_tool.metadata.name}, {weather_tool.metadata.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "print(geocode_location(\"Brisbane, QLD\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Weather Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "weather_agent = OpenAIAgent.from_tools(\n",
    "    tools=[geocode_tool, weather_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"You are a Weather Verification Agent for insurance.\n",
    "\n",
    "1. Use geocode_location to get coordinates\n",
    "2. Use get_bom_weather to fetch weather data\n",
    "3. Compile a structured report\n",
    "\n",
    "Include: location, coordinates, date, events, thunderstorm status, wind status.\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Weather agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run weather agent\n",
    "def run_weather_agent(location: str, date: str):\n",
    "    print(f\"\\n[Weather Agent] Verifying {location} on {date}\")\n",
    "    response = weather_agent.chat(f\"Verify weather for {location} on {date}\")\n",
    "    return str(response)\n",
    "\n",
    "weather_report = run_weather_agent(\"Brisbane, QLD\", \"2025-03-07\")\n",
    "print(\"\\nReport:\")\n",
    "print(weather_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Eligibility Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_agent = OpenAIAgent.from_tools(\n",
    "    tools=[],  # No tools\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"You are a Claims Eligibility Agent.\n",
    "\n",
    "Rules:\n",
    "- APPROVED: Both thunderstorms AND strong winds detected in Australia\n",
    "- REVIEW: Only one severe weather type detected\n",
    "- DENIED: No severe weather or outside Australia\n",
    "\n",
    "Provide: DECISION, REASONING, CONFIDENCE (High/Medium/Low)\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def run_eligibility_agent(weather_report: str):\n",
    "    print(\"\\n[Eligibility Agent] Determining...\")\n",
    "    response = eligibility_agent.chat(f\"Determine eligibility:\\n\\n{weather_report}\")\n",
    "    return str(response)\n",
    "\n",
    "eligibility_result = run_eligibility_agent(weather_report)\n",
    "print(\"\\nDecision:\")\n",
    "print(eligibility_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_claim(location: str, date: str):\n",
    "    \"\"\"Run complete claims pipeline.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Processing: {location} on {date}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Reset agent memory\n",
    "    weather_agent.reset()\n",
    "    eligibility_agent.reset()\n",
    "    \n",
    "    # Step 1: Weather\n",
    "    weather_report = run_weather_agent(location, date)\n",
    "    \n",
    "    # Step 2: Eligibility\n",
    "    eligibility_result = run_eligibility_agent(weather_report)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(eligibility_result)\n",
    "    \n",
    "    return {\"weather\": weather_report, \"decision\": eligibility_result}\n",
    "\n",
    "result = process_claim(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. DSPy Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "dspy_lm = dspy.LM(model=f\"openai/{model_name}\", api_key=api_key, api_base=api_base)\n",
    "dspy.configure(lm=dspy_lm)\n",
    "\n",
    "class EligSig(dspy.Signature):\n",
    "    \"\"\"CAT eligibility.\"\"\"\n",
    "    weather_report: str = dspy.InputField()\n",
    "    decision: str = dspy.OutputField(desc=\"APPROVED/REVIEW/DENIED\")\n",
    "    reasoning: str = dspy.OutputField()\n",
    "\n",
    "elig_mod = dspy.ChainOfThought(EligSig)\n",
    "\n",
    "# Optimize\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(weather_report=\"Thunder+Wind. Both: True\", decision=\"APPROVED\", reasoning=\"Both met\").with_inputs(\"weather_report\"),\n",
    "    dspy.Example(weather_report=\"Rain. Both: False\", decision=\"DENIED\", reasoning=\"No severe\").with_inputs(\"weather_report\"),\n",
    "    dspy.Example(weather_report=\"Thunder only. Wind: False\", decision=\"REVIEW\", reasoning=\"One met\").with_inputs(\"weather_report\"),\n",
    "]\n",
    "\n",
    "metric = lambda ex, pred, trace=None: ex.decision.upper() == pred.decision.upper()\n",
    "optimizer = BootstrapFewShot(metric=metric, max_bootstrapped_demos=2)\n",
    "optimized_mod = optimizer.compile(elig_mod, trainset=examples)\n",
    "\n",
    "print(\"DSPy optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy-enhanced pipeline\n",
    "def process_with_dspy(location: str, date: str):\n",
    "    weather_agent.reset()\n",
    "    \n",
    "    print(f\"\\n[DSPy Pipeline] {location} on {date}\")\n",
    "    weather_report = run_weather_agent(location, date)\n",
    "    \n",
    "    r = optimized_mod(weather_report=weather_report)\n",
    "    print(f\"\\nDSPy Decision: {r.decision}\")\n",
    "    print(f\"Reasoning: {r.reasoning}\")\n",
    "    \n",
    "    return {\"weather\": weather_report, \"decision\": r.decision, \"reasoning\": r.reasoning}\n",
    "\n",
    "dspy_result = process_with_dspy(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLFlow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_experiment(\"llamaindex-claims\")\n",
    "\n",
    "def run_tracked(location: str, date: str, use_dspy: bool = False):\n",
    "    run_name = f\"llama_{location.split(',')[0]}\"\n",
    "    if use_dspy:\n",
    "        run_name += \"_dspy\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\"framework\": \"llamaindex\", \"model\": model_name, \"use_dspy\": use_dspy})\n",
    "        \n",
    "        start = datetime.now()\n",
    "        \n",
    "        if use_dspy:\n",
    "            result = process_with_dspy(location, date)\n",
    "        else:\n",
    "            result = process_claim(location, date)\n",
    "        \n",
    "        duration = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        decision = \"UNKNOWN\"\n",
    "        for d in [\"APPROVED\", \"DENIED\", \"REVIEW\"]:\n",
    "            if d in str(result.get(\"decision\", \"\")).upper():\n",
    "                decision = d\n",
    "                break\n",
    "        \n",
    "        mlflow.log_metrics({\"duration\": duration})\n",
    "        mlflow.set_tags({\"decision\": decision})\n",
    "        \n",
    "        print(f\"Logged: {decision}, {duration:.2f}s\")\n",
    "\n",
    "run_tracked(\"Brisbane, QLD\", \"2025-03-07\", use_dspy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Covered\n",
    "- LlamaIndex FunctionTool and agents\n",
    "- OpenAIAgent for tool calling\n",
    "- DSPy + MLFlow integration\n",
    "\n",
    "### Strengths\n",
    "- Excellent for RAG applications\n",
    "- Strong data connector ecosystem\n",
    "- Good documentation\n",
    "\n",
    "### Challenges\n",
    "- Less agent-focused than some frameworks\n",
    "- API changes between versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tutorial complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
