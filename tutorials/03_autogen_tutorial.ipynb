{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen 0.4 Tutorial: Building AI Agents for Insurance\n",
    "\n",
    "This tutorial introduces **AutoGen 0.4+**, Microsoft's framework for building multi-agent AI systems. AutoGen excels at creating conversational agents that can collaborate through structured conversations.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. AutoGen's core concepts: Agents, Tools, and Group Chat\n",
    "2. Building a Weather Verification Agent with tool calling\n",
    "3. Building a Claims Eligibility Agent for business logic\n",
    "4. Orchestrating multi-agent conversations\n",
    "5. Integrating DSPy for prompt optimization\n",
    "6. Using MLFlow for experiment tracking\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- OpenAI API key (or compatible API like z.ai)\n",
    "- Basic understanding of async Python\n",
    "\n",
    "---\n",
    "\n",
    "## Important: AutoGen 0.4 Breaking Changes\n",
    "\n",
    "If you've used AutoGen before (v0.2.x), **version 0.4 is a complete rewrite**:\n",
    "\n",
    "| AutoGen 0.2.x | AutoGen 0.4+ |\n",
    "|---------------|---------------|\n",
    "| `autogen.AssistantAgent` | `autogen_agentchat.agents.AssistantAgent` |\n",
    "| `autogen.UserProxyAgent` | Not used - tools go directly on agents |\n",
    "| Synchronous API | Async-first (`await agent.on_messages()`) |\n",
    "| `initiate_chat()` | `GroupChat` or direct message passing |\n",
    "\n",
    "**Your old AutoGen code will NOT work.** This tutorial covers the new 0.4 API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "AutoGen 0.4 is split into multiple packages. Install the core packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGen 0.4+ packages\n",
    "# !pip install autogen-agentchat autogen-ext[openai]\n",
    "\n",
    "# Additional dependencies for our weather example\n",
    "# !pip install httpx beautifulsoup4 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is set\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "# Optional: Use alternative API endpoint (e.g., z.ai)\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"API base: {api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Concepts: AutoGen's Architecture\n",
    "\n",
    "AutoGen 0.4 is built around several key concepts:\n",
    "\n",
    "### 2.1 Agents\n",
    "\n",
    "Agents are autonomous entities that can:\n",
    "- Process messages\n",
    "- Call tools (functions)\n",
    "- Generate responses using an LLM\n",
    "\n",
    "```python\n",
    "# The main agent type in AutoGen 0.4\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"my_agent\",\n",
    "    model_client=model_client,  # LLM connection\n",
    "    tools=[my_function],         # Python functions the agent can call\n",
    "    system_message=\"Your role...\"\n",
    ")\n",
    "```\n",
    "\n",
    "### 2.2 Model Clients\n",
    "\n",
    "Model clients handle communication with LLM providers:\n",
    "\n",
    "```python\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=\"...\",\n",
    "    base_url=\"...\"  # For alternative APIs\n",
    ")\n",
    "```\n",
    "\n",
    "### 2.3 Tools (Functions)\n",
    "\n",
    "Tools are regular Python functions that agents can call. AutoGen automatically:\n",
    "- Generates JSON schemas from function signatures\n",
    "- Handles argument passing\n",
    "- Supports both sync and async functions\n",
    "\n",
    "```python\n",
    "async def my_tool(param: str) -> str:\n",
    "    \"\"\"Tool description for the LLM.\"\"\"\n",
    "    return f\"Result for {param}\"\n",
    "```\n",
    "\n",
    "### 2.4 Group Chat\n",
    "\n",
    "Multi-agent orchestration happens through group chats:\n",
    "\n",
    "```python\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[agent1, agent2],\n",
    "    termination_condition=MaxMessageTermination(max_messages=10)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Tools for Weather Verification\n",
    "\n",
    "Let's create the tools our Weather Agent will use. In AutoGen, tools are simply async functions with docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional\n",
    "\n",
    "async def geocode_location(location: str, country: str = \"Australia\") -> dict:\n",
    "    \"\"\"\n",
    "    Convert a location name to latitude/longitude coordinates using Nominatim.\n",
    "    \n",
    "    Args:\n",
    "        location: Address or place name (e.g., 'Brisbane, QLD')\n",
    "        country: Country to search within (default: Australia)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with lat, lon, and display_name, or error message\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(\n",
    "            \"https://nominatim.openstreetmap.org/search\",\n",
    "            params={\n",
    "                \"q\": f\"{location}, {country}\",\n",
    "                \"format\": \"json\",\n",
    "                \"limit\": 1\n",
    "            },\n",
    "            headers={\"User-Agent\": \"InsuranceWeatherBot/1.0\"},\n",
    "            timeout=10.0\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return {\"error\": f\"Geocoding failed: HTTP {response.status_code}\"}\n",
    "        \n",
    "        data = response.json()\n",
    "        if not data:\n",
    "            return {\"error\": f\"Location not found: {location}\"}\n",
    "        \n",
    "        result = data[0]\n",
    "        return {\n",
    "            \"lat\": float(result[\"lat\"]),\n",
    "            \"lon\": float(result[\"lon\"]),\n",
    "            \"display_name\": result[\"display_name\"]\n",
    "        }\n",
    "\n",
    "# Test the geocoding tool\n",
    "result = await geocode_location(\"Brisbane, QLD\")\n",
    "print(f\"Geocoding result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_bom_weather(\n",
    "    latitude: float,\n",
    "    longitude: float,\n",
    "    date: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Fetch weather observations from Australian Bureau of Meteorology.\n",
    "    \n",
    "    Args:\n",
    "        latitude: Latitude coordinate (e.g., -27.4698)\n",
    "        longitude: Longitude coordinate (e.g., 153.0251)\n",
    "        date: Date in YYYY-MM-DD format\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with weather events found at this location\n",
    "    \"\"\"\n",
    "    # Parse date components\n",
    "    try:\n",
    "        year, month, day = date.split(\"-\")\n",
    "    except ValueError:\n",
    "        return {\"error\": f\"Invalid date format: {date}. Use YYYY-MM-DD\"}\n",
    "    \n",
    "    # Query BOM storms database\n",
    "    url = \"https://reg.bom.gov.au/cgi-bin/climate/storms/get_storms.py\"\n",
    "    params = {\n",
    "        \"begin_day\": day,\n",
    "        \"begin_month\": month,\n",
    "        \"begin_year\": year,\n",
    "        \"end_day\": day,\n",
    "        \"end_month\": month,\n",
    "        \"end_year\": year,\n",
    "        \"lat\": latitude,\n",
    "        \"lng\": longitude,\n",
    "        \"event\": \"all\",\n",
    "        \"distance_from_point\": \"50\",  # 50km radius\n",
    "        \"states\": \"all\"\n",
    "    }\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, params=params, timeout=15.0)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return {\"error\": f\"BOM API failed: HTTP {response.status_code}\"}\n",
    "        \n",
    "        # Parse HTML response\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract weather events from table\n",
    "        events = []\n",
    "        rows = soup.find_all('tr')\n",
    "        \n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 2:\n",
    "                event_type = cells[0].get_text(strip=True)\n",
    "                if event_type:\n",
    "                    events.append(event_type)\n",
    "        \n",
    "        # Categorize events\n",
    "        has_thunderstorm = any(\n",
    "            'thunder' in e.lower() or 'lightning' in e.lower()\n",
    "            for e in events\n",
    "        )\n",
    "        has_strong_wind = any(\n",
    "            'wind' in e.lower() or 'gust' in e.lower()\n",
    "            for e in events\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"date\": date,\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"events_found\": events,\n",
    "            \"has_thunderstorm\": has_thunderstorm,\n",
    "            \"has_strong_wind\": has_strong_wind,\n",
    "            \"event_count\": len(events)\n",
    "        }\n",
    "\n",
    "# Test the weather tool\n",
    "weather = await get_bom_weather(-27.4698, 153.0251, \"2025-03-07\")\n",
    "print(f\"Weather data: {weather}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the Weather Verification Agent\n",
    "\n",
    "Now let's create an AutoGen agent that uses these tools to verify weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the model client\n",
    "# CRITICAL: For non-OpenAI APIs, you MUST set base_url\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=model_name,\n",
    "    api_key=api_key,\n",
    "    base_url=api_base if api_base != \"https://api.openai.com/v1\" else None\n",
    ")\n",
    "\n",
    "# Create the Weather Verification Agent\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"WeatherVerificationAgent\",\n",
    "    model_client=model_client,\n",
    "    tools=[geocode_location, get_bom_weather],\n",
    "    system_message=\"\"\"You are a Weather Verification Agent for an Australian insurance company.\n",
    "\n",
    "Your job is to verify weather conditions for insurance claims by:\n",
    "1. Using geocode_location to convert addresses to coordinates\n",
    "2. Using get_bom_weather to fetch weather data from the Bureau of Meteorology\n",
    "\n",
    "Always provide a structured summary including:\n",
    "- Location verified (with coordinates)\n",
    "- Date checked\n",
    "- Weather events found\n",
    "- Whether thunderstorms were detected\n",
    "- Whether strong winds were detected\n",
    "\n",
    "Be precise and factual. Do not speculate about events not found in the data.\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Weather Agent created: {weather_agent.name}\")\n",
    "print(f\"Tools available: {[t.__name__ for t in weather_agent._tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Claims Eligibility Agent\n",
    "\n",
    "This agent applies business rules to determine CAT event eligibility. It has no tools - just LLM reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Claims Eligibility Agent\n",
    "eligibility_agent = AssistantAgent(\n",
    "    name=\"ClaimsEligibilityAgent\",\n",
    "    model_client=model_client,\n",
    "    tools=[],  # No tools - pure reasoning\n",
    "    system_message=\"\"\"You are a Claims Eligibility Agent for an Australian insurance company.\n",
    "\n",
    "Your job is to determine whether a weather event qualifies as a Catastrophic (CAT) event\n",
    "based on the weather verification data provided.\n",
    "\n",
    "## CAT Event Eligibility Rules\n",
    "\n",
    "**APPROVED** - Qualifies as CAT event if ALL conditions met:\n",
    "- Location is within Australia (lat: -44 to -10, lon: 112 to 154)\n",
    "- Date is within the last 90 days and not in the future\n",
    "- BOTH thunderstorms AND strong winds were detected\n",
    "\n",
    "**REVIEW** - Needs manual review if:\n",
    "- Only ONE weather type (thunderstorms OR strong winds) was detected\n",
    "- Location is near Australian borders\n",
    "\n",
    "**DENIED** - Does not qualify if:\n",
    "- Neither thunderstorms nor strong winds detected\n",
    "- Location is outside Australia\n",
    "- Date is invalid or too old\n",
    "\n",
    "## Response Format\n",
    "\n",
    "Always provide:\n",
    "1. **Decision**: APPROVED, REVIEW, or DENIED\n",
    "2. **Reasoning**: Brief explanation of why\n",
    "3. **Confidence**: High, Medium, or Low\n",
    "4. **Recommendations**: Any follow-up actions needed\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Eligibility Agent created: {eligibility_agent.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Single Agent Interaction\n",
    "\n",
    "Before setting up multi-agent communication, let's test each agent individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def test_weather_agent():\n",
    "    \"\"\"Test the weather agent with a sample query.\"\"\"\n",
    "    \n",
    "    # Create a user message\n",
    "    user_message = TextMessage(\n",
    "        content=\"Please verify weather conditions for Brisbane, QLD on 2025-03-07\",\n",
    "        source=\"user\"\n",
    "    )\n",
    "    \n",
    "    # Send to agent and get response\n",
    "    response = await weather_agent.on_messages(\n",
    "        messages=[user_message],\n",
    "        cancellation_token=CancellationToken()\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Weather Agent Response:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(response.chat_message.content)\n",
    "    \n",
    "    return response.chat_message.content\n",
    "\n",
    "# Run the test\n",
    "weather_report = await test_weather_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Agent Orchestration with Group Chat\n",
    "\n",
    "AutoGen's power comes from its multi-agent orchestration. Let's set up a group chat where agents collaborate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "async def run_claims_pipeline(location: str, date: str):\n",
    "    \"\"\"\n",
    "    Run the full claims verification pipeline with both agents.\n",
    "    \n",
    "    Flow: User -> Weather Agent -> Eligibility Agent -> Final Decision\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create termination conditions\n",
    "    # Stop when \"APPROVED\", \"DENIED\", or \"REVIEW\" appears in message\n",
    "    termination = TextMentionTermination(\"DECISION:\") | MaxMessageTermination(max_messages=10)\n",
    "    \n",
    "    # Create the group chat team\n",
    "    # RoundRobinGroupChat: Agents take turns in order\n",
    "    team = RoundRobinGroupChat(\n",
    "        participants=[weather_agent, eligibility_agent],\n",
    "        termination_condition=termination\n",
    "    )\n",
    "    \n",
    "    # Create the task\n",
    "    task = f\"\"\"Process this insurance claim:\n",
    "    \n",
    "Location: {location}\n",
    "Date of Incident: {date}\n",
    "\n",
    "Weather Agent: Please verify the weather conditions for this location and date.\n",
    "Eligibility Agent: Once weather data is available, determine CAT event eligibility.\n",
    "\n",
    "Eligibility Agent must end with 'DECISION: [APPROVED/REVIEW/DENIED]'\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Processing claim for {location} on {date}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Run the team and stream to console\n",
    "    result = await Console(team.run_stream(task=task))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the full pipeline\n",
    "result = await run_claims_pipeline(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Alternative: Selector Group Chat\n",
    "\n",
    "For more complex workflows, you can use `SelectorGroupChat` where an LLM decides which agent speaks next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "\n",
    "async def run_selector_pipeline(location: str, date: str):\n",
    "    \"\"\"\n",
    "    Run claims pipeline with intelligent agent selection.\n",
    "    The model decides which agent should respond based on context.\n",
    "    \"\"\"\n",
    "    \n",
    "    termination = TextMentionTermination(\"DECISION:\") | MaxMessageTermination(max_messages=10)\n",
    "    \n",
    "    # SelectorGroupChat: LLM picks the next speaker\n",
    "    team = SelectorGroupChat(\n",
    "        participants=[weather_agent, eligibility_agent],\n",
    "        model_client=model_client,  # Uses LLM to select speaker\n",
    "        termination_condition=termination,\n",
    "        selector_prompt=\"\"\"Select the next agent based on the conversation:\n",
    "        \n",
    "- WeatherVerificationAgent: Select when location/weather needs to be verified\n",
    "- ClaimsEligibilityAgent: Select when weather data is available and eligibility needs to be determined\n",
    "\n",
    "Current agents: {participants}\n",
    "\n",
    "Read the conversation and select the most appropriate next speaker.\"\"\"\n",
    "    )\n",
    "    \n",
    "    task = f\"\"\"New insurance claim to process:\n",
    "    \n",
    "Location: {location}\n",
    "Incident Date: {date}\n",
    "\n",
    "Please verify weather and determine CAT eligibility.\n",
    "End with 'DECISION: [APPROVED/REVIEW/DENIED]'\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Selector GroupChat: {location} on {date}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = await Console(team.run_stream(task=task))\n",
    "    return result\n",
    "\n",
    "# Uncomment to test (uses more API calls due to selector)\n",
    "# result = await run_selector_pipeline(\"Sydney, NSW\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Testing Multiple Claims\n",
    "\n",
    "Let's test the pipeline with multiple scenarios to see different outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases representing different scenarios\n",
    "test_claims = [\n",
    "    # Likely to have storm activity (QLD)\n",
    "    (\"Brisbane, QLD, 4000\", \"2025-03-07\"),\n",
    "    # Suburban area (QLD)\n",
    "    (\"Mcdowall, QLD, 4053\", \"2025-03-07\"),\n",
    "    # Major city (NSW)\n",
    "    (\"Sydney, NSW, 2000\", \"2025-03-07\"),\n",
    "    # Likely calm weather (WA summer)\n",
    "    (\"Perth, WA, 6000\", \"2025-01-15\"),\n",
    "]\n",
    "\n",
    "async def test_all_claims():\n",
    "    \"\"\"Run all test claims through the pipeline.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for location, date in test_claims:\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Testing: {location} on {date}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            result = await run_claims_pipeline(location, date)\n",
    "            results.append((location, date, \"Success\", result))\n",
    "        except Exception as e:\n",
    "            results.append((location, date, \"Error\", str(e)))\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        await asyncio.sleep(1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run one test (comment out to run all)\n",
    "result = await run_claims_pipeline(\"Brisbane, QLD, 4000\", \"2025-03-07\")\n",
    "\n",
    "# Uncomment to run all tests\n",
    "# results = await test_all_claims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. DSPy Integration for Prompt Optimization\n",
    "\n",
    "DSPy can optimize the prompts used in AutoGen agents. This section shows how to:\n",
    "1. Create DSPy modules that mirror your agent behavior\n",
    "2. Optimize prompts using DSPy compilers\n",
    "3. Export optimized prompts back to AutoGen\n",
    "\n",
    "### Why DSPy + AutoGen?\n",
    "\n",
    "- **AutoGen**: Great for multi-agent orchestration\n",
    "- **DSPy**: Great for prompt optimization\n",
    "- **Combined**: Optimized prompts in sophisticated agent workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DSPy if needed\n",
    "# !pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Configure DSPy to use the same LLM\n",
    "dspy_lm = dspy.LM(\n",
    "    model=f\"openai/{model_name}\",\n",
    "    api_key=api_key,\n",
    "    api_base=api_base\n",
    ")\n",
    "dspy.configure(lm=dspy_lm)\n",
    "\n",
    "print(f\"DSPy configured with model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DSPy Signature for eligibility determination\n",
    "class EligibilitySignature(dspy.Signature):\n",
    "    \"\"\"Determine if a weather event qualifies as a CAT event for insurance.\"\"\"\n",
    "    \n",
    "    weather_report: str = dspy.InputField(\n",
    "        desc=\"Weather verification report with events, location, and date\"\n",
    "    )\n",
    "    \n",
    "    decision: str = dspy.OutputField(\n",
    "        desc=\"One of: APPROVED, REVIEW, or DENIED\"\n",
    "    )\n",
    "    \n",
    "    reasoning: str = dspy.OutputField(\n",
    "        desc=\"Brief explanation for the decision\"\n",
    "    )\n",
    "    \n",
    "    confidence: str = dspy.OutputField(\n",
    "        desc=\"Confidence level: High, Medium, or Low\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a DSPy module using Chain of Thought\n",
    "eligibility_module = dspy.ChainOfThought(EligibilitySignature)\n",
    "\n",
    "# Test it\n",
    "test_report = \"\"\"\n",
    "Location: Brisbane, Queensland, Australia\n",
    "Coordinates: -27.4698, 153.0251\n",
    "Date: 2025-03-07\n",
    "Events Found: Thunderstorm, Strong Wind Gust\n",
    "Has Thunderstorm: True\n",
    "Has Strong Wind: True\n",
    "\"\"\"\n",
    "\n",
    "result = eligibility_module(weather_report=test_report)\n",
    "print(f\"Decision: {result.decision}\")\n",
    "print(f\"Reasoning: {result.reasoning}\")\n",
    "print(f\"Confidence: {result.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Optimize with Training Examples\n",
    "\n",
    "DSPy can learn from examples to improve its prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "training_examples = [\n",
    "    dspy.Example(\n",
    "        weather_report=\"\"\"Location: Brisbane, QLD. Coordinates: -27.47, 153.02.\n",
    "        Date: 2025-03-07. Events: Thunderstorm, Wind Gust 85km/h.\n",
    "        Has Thunderstorm: True. Has Strong Wind: True.\"\"\",\n",
    "        decision=\"APPROVED\",\n",
    "        reasoning=\"Both thunderstorm and strong wind confirmed in valid Australian location within 90 days\",\n",
    "        confidence=\"High\"\n",
    "    ).with_inputs(\"weather_report\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        weather_report=\"\"\"Location: Sydney, NSW. Coordinates: -33.87, 151.21.\n",
    "        Date: 2025-03-07. Events: Light Rain.\n",
    "        Has Thunderstorm: False. Has Strong Wind: False.\"\"\",\n",
    "        decision=\"DENIED\",\n",
    "        reasoning=\"No severe weather events detected - only light rain\",\n",
    "        confidence=\"High\"\n",
    "    ).with_inputs(\"weather_report\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        weather_report=\"\"\"Location: Melbourne, VIC. Coordinates: -37.81, 144.96.\n",
    "        Date: 2025-03-07. Events: Thunderstorm.\n",
    "        Has Thunderstorm: True. Has Strong Wind: False.\"\"\",\n",
    "        decision=\"REVIEW\",\n",
    "        reasoning=\"Only one severe weather type detected - needs manual review\",\n",
    "        confidence=\"Medium\"\n",
    "    ).with_inputs(\"weather_report\"),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(training_examples)} training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple metric for evaluation\n",
    "def eligibility_metric(example, prediction, trace=None):\n",
    "    \"\"\"Check if the prediction matches the expected decision.\"\"\"\n",
    "    # Normalize decisions for comparison\n",
    "    expected = example.decision.upper().strip()\n",
    "    predicted = prediction.decision.upper().strip()\n",
    "    \n",
    "    return expected == predicted\n",
    "\n",
    "# Test current performance\n",
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluator = Evaluate(\n",
    "    devset=training_examples,\n",
    "    metric=eligibility_metric,\n",
    "    num_threads=1,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_score = evaluator(eligibility_module)\n",
    "print(f\"Baseline accuracy: {baseline_score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize with BootstrapFewShot (simple optimizer)\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=eligibility_metric,\n",
    "    max_bootstrapped_demos=2,\n",
    "    max_labeled_demos=2\n",
    ")\n",
    "\n",
    "# Compile the optimized module\n",
    "optimized_eligibility = optimizer.compile(\n",
    "    eligibility_module,\n",
    "    trainset=training_examples\n",
    ")\n",
    "\n",
    "# Evaluate optimized version\n",
    "optimized_score = evaluator(optimized_eligibility)\n",
    "print(f\"Optimized accuracy: {optimized_score}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Export Optimized Prompt to AutoGen\n",
    "\n",
    "Extract the optimized prompt and use it in AutoGen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dspy_prompt(module) -> str:\n",
    "    \"\"\"\n",
    "    Extract the prompt from a DSPy module for use in other frameworks.\n",
    "    \"\"\"\n",
    "    # Get the signature\n",
    "    sig = module.signature if hasattr(module, 'signature') else module.predict.signature\n",
    "    \n",
    "    # Build prompt from signature\n",
    "    prompt_parts = []\n",
    "    \n",
    "    # Add docstring as instructions\n",
    "    if sig.__doc__:\n",
    "        prompt_parts.append(f\"Task: {sig.__doc__}\\n\")\n",
    "    \n",
    "    # Add any demos (few-shot examples)\n",
    "    if hasattr(module, 'demos') and module.demos:\n",
    "        prompt_parts.append(\"## Examples\\n\")\n",
    "        for i, demo in enumerate(module.demos, 1):\n",
    "            prompt_parts.append(f\"### Example {i}\")\n",
    "            for field, value in demo.items():\n",
    "                prompt_parts.append(f\"{field}: {value}\")\n",
    "            prompt_parts.append(\"\")\n",
    "    \n",
    "    # Add input/output field descriptions\n",
    "    prompt_parts.append(\"## Input Fields\")\n",
    "    for name, field in sig.input_fields.items():\n",
    "        desc = field.json_schema_extra.get('desc', '') if hasattr(field, 'json_schema_extra') else ''\n",
    "        prompt_parts.append(f\"- {name}: {desc}\")\n",
    "    \n",
    "    prompt_parts.append(\"\\n## Output Fields\")\n",
    "    for name, field in sig.output_fields.items():\n",
    "        desc = field.json_schema_extra.get('desc', '') if hasattr(field, 'json_schema_extra') else ''\n",
    "        prompt_parts.append(f\"- {name}: {desc}\")\n",
    "    \n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "# Extract the optimized prompt\n",
    "optimized_prompt = extract_dspy_prompt(optimized_eligibility)\n",
    "print(\"Extracted prompt for AutoGen:\")\n",
    "print(\"=\" * 60)\n",
    "print(optimized_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimized AutoGen agent with the DSPy-enhanced prompt\n",
    "enhanced_system_message = f\"\"\"You are a Claims Eligibility Agent optimized with DSPy.\n",
    "\n",
    "{optimized_prompt}\n",
    "\n",
    "## Business Rules\n",
    "\n",
    "**APPROVED**: Both thunderstorms AND strong winds detected in valid Australian location\n",
    "**REVIEW**: Only one severe weather type detected\n",
    "**DENIED**: No severe weather or invalid location/date\n",
    "\n",
    "Always end your response with:\n",
    "DECISION: [APPROVED/REVIEW/DENIED]\n",
    "\"\"\"\n",
    "\n",
    "# Create the enhanced agent\n",
    "enhanced_eligibility_agent = AssistantAgent(\n",
    "    name=\"EnhancedClaimsAgent\",\n",
    "    model_client=model_client,\n",
    "    tools=[],\n",
    "    system_message=enhanced_system_message\n",
    ")\n",
    "\n",
    "print(\"Enhanced eligibility agent created with DSPy-optimized prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. MLFlow Integration for Experiment Tracking\n",
    "\n",
    "MLFlow helps you track experiments, compare agent performance, and manage model versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLFlow if needed\n",
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up MLFlow experiment\n",
    "mlflow.set_experiment(\"autogen-weather-claims\")\n",
    "\n",
    "print(f\"MLFlow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: autogen-weather-claims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_tracked_pipeline(location: str, date: str, run_name: str = None):\n",
    "    \"\"\"\n",
    "    Run the claims pipeline with MLFlow tracking.\n",
    "    \"\"\"\n",
    "    \n",
    "    run_name = run_name or f\"claim_{location.split(',')[0]}_{date}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"framework\": \"autogen\",\n",
    "            \"autogen_version\": \"0.4\",\n",
    "            \"model\": model_name,\n",
    "            \"location\": location,\n",
    "            \"date\": date,\n",
    "            \"orchestration_type\": \"RoundRobinGroupChat\"\n",
    "        })\n",
    "        \n",
    "        # Track timing\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Create team for this run\n",
    "            termination = TextMentionTermination(\"DECISION:\") | MaxMessageTermination(max_messages=10)\n",
    "            team = RoundRobinGroupChat(\n",
    "                participants=[weather_agent, enhanced_eligibility_agent],\n",
    "                termination_condition=termination\n",
    "            )\n",
    "            \n",
    "            task = f\"\"\"Process insurance claim:\n",
    "            Location: {location}\n",
    "            Date: {date}\n",
    "            End with 'DECISION: [APPROVED/REVIEW/DENIED]'\"\"\"\n",
    "            \n",
    "            # Run and collect messages\n",
    "            messages = []\n",
    "            async for message in team.run_stream(task=task):\n",
    "                if hasattr(message, 'content'):\n",
    "                    messages.append({\n",
    "                        \"source\": getattr(message, 'source', 'unknown'),\n",
    "                        \"content\": str(message.content)[:500]  # Truncate long messages\n",
    "                    })\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # Extract decision from final message\n",
    "            final_content = messages[-1][\"content\"] if messages else \"\"\n",
    "            decision = \"UNKNOWN\"\n",
    "            for d in [\"APPROVED\", \"DENIED\", \"REVIEW\"]:\n",
    "                if d in final_content.upper():\n",
    "                    decision = d\n",
    "                    break\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                \"duration_seconds\": duration,\n",
    "                \"message_count\": len(messages),\n",
    "                \"success\": 1\n",
    "            })\n",
    "            \n",
    "            # Log artifacts\n",
    "            mlflow.log_dict(messages, \"conversation.json\")\n",
    "            \n",
    "            # Log tags\n",
    "            mlflow.set_tags({\n",
    "                \"decision\": decision,\n",
    "                \"status\": \"success\"\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nRun logged to MLFlow\")\n",
    "            print(f\"Decision: {decision}\")\n",
    "            print(f\"Duration: {duration:.2f}s\")\n",
    "            print(f\"Messages: {len(messages)}\")\n",
    "            \n",
    "            return {\n",
    "                \"decision\": decision,\n",
    "                \"duration\": duration,\n",
    "                \"messages\": messages\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            mlflow.log_metrics({\"success\": 0})\n",
    "            mlflow.set_tags({\"status\": \"error\", \"error\": str(e)[:100]})\n",
    "            raise\n",
    "\n",
    "# Run with tracking\n",
    "result = await run_tracked_pipeline(\"Brisbane, QLD\", \"2025-03-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log DSPy optimization results to MLFlow\n",
    "with mlflow.start_run(run_name=\"dspy_optimization\"):\n",
    "    mlflow.log_params({\n",
    "        \"optimizer\": \"BootstrapFewShot\",\n",
    "        \"training_examples\": len(training_examples),\n",
    "        \"max_bootstrapped_demos\": 2\n",
    "    })\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"baseline_accuracy\": baseline_score,\n",
    "        \"optimized_accuracy\": optimized_score,\n",
    "        \"improvement\": optimized_score - baseline_score\n",
    "    })\n",
    "    \n",
    "    # Save the optimized prompt as artifact\n",
    "    mlflow.log_text(optimized_prompt, \"optimized_prompt.txt\")\n",
    "    mlflow.log_text(enhanced_system_message, \"enhanced_system_message.txt\")\n",
    "    \n",
    "    print(\"DSPy optimization results logged to MLFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View experiment results\n",
    "experiment = mlflow.get_experiment_by_name(\"autogen-weather-claims\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "print(\"\\nExperiment Runs:\")\n",
    "print(\"=\" * 60)\n",
    "if len(runs) > 0:\n",
    "    display_cols = ['run_id', 'status', 'start_time']\n",
    "    # Add metric columns if they exist\n",
    "    for col in runs.columns:\n",
    "        if col.startswith('metrics.') or col.startswith('params.') or col.startswith('tags.'):\n",
    "            display_cols.append(col)\n",
    "    print(runs[[c for c in display_cols if c in runs.columns]].to_string())\n",
    "else:\n",
    "    print(\"No runs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary & Key Takeaways\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "1. **AutoGen 0.4 Architecture**: Agents, Model Clients, Tools, and Group Chats\n",
    "2. **Breaking Changes**: Complete rewrite from 0.2.x - old code won't work\n",
    "3. **Tool Definition**: Simple async functions with type hints\n",
    "4. **Multi-Agent Orchestration**: RoundRobinGroupChat and SelectorGroupChat\n",
    "5. **DSPy Integration**: Optimize prompts and export to AutoGen\n",
    "6. **MLFlow Tracking**: Log experiments, metrics, and artifacts\n",
    "\n",
    "### AutoGen Strengths\n",
    "\n",
    "- Powerful multi-agent orchestration\n",
    "- Clean async-first design\n",
    "- Flexible conversation patterns\n",
    "- Good for complex agent interactions\n",
    "\n",
    "### AutoGen Challenges\n",
    "\n",
    "- Steep learning curve (especially migrating from 0.2.x)\n",
    "- Less type safety than Pydantic AI\n",
    "- Documentation still catching up to 0.4 changes\n",
    "\n",
    "### For Insurance Teams\n",
    "\n",
    "- **Consider AutoGen if**: You need complex multi-agent workflows with conversation\n",
    "- **Consider alternatives if**: You need maximum type safety (Pydantic AI) or simpler workflows\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with different GroupChat types\n",
    "2. Add more training examples to DSPy\n",
    "3. Compare results across different models\n",
    "4. Explore AutoGen's human-in-the-loop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup - reset agents for fresh runs\n",
    "await weather_agent.reset()\n",
    "await eligibility_agent.reset()\n",
    "await enhanced_eligibility_agent.reset()\n",
    "\n",
    "print(\"Agents reset. Tutorial complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
